import 'dotenv/config';
import { Scheduler } from './core/Scheduler';
import { Agent } from './core/Agent';
import { ContextManager } from './memory/ContextManager';
import { SummaryStore } from './memory/SummaryStore';
import { ToolRegistry } from './core/ToolRegistry';
import { BrowserService } from './services/BrowserService';
import { ActionQueueService } from './services/ActionQueueService';
import { WhatsAppService } from './services/whatsappService';
import { MediaService } from './services/mediaService';
import { OpenAIService, createOpenAIServiceFromConfig } from './services/openaiService';
import { WebScrapeService, createWebScrapeService } from './services/webScrapeService';
import { GoogleSearchService, createGoogleSearchServiceFromEnv } from './services/googleSearchService';
import { WebSearchTool } from './tools/WebSearchTool';
import { RecallHistoryTool } from './tools/RecallHistoryTool';
import { ScrapeNewsTool } from './tools/ScrapeNewsTool';
import { DeepResearchTool } from './tools/DeepResearchTool'; // Import the new tool
import { NewsScrapeService, createNewsScrapeService } from './services/newsScrapeService';
import { NewsProcessorService } from './services/newsProcessorService';
import { DatabaseConfig } from './config/databaseConfig';
import type { KnowledgeDocument } from './memory/KnowledgeBasePostgres';
import * as fs from 'fs'; // Added for reading generated audio files

/**
 * Autonomous WhatsApp Agent Main Entry Point
 * 
 * This is the complete replacement for the reactive bot architecture.
 * Features autonomous browsing, proactive messaging, and intelligent memory management.
 */
class AutonomousWhatsAppAgent {
  private scheduler?: Scheduler;
  private agent?: Agent;
  private contextMgr?: ContextManager;
  private kb?: any; // KnowledgeBase or KnowledgeBasePostgres
  private tools?: ToolRegistry;
  private browser?: BrowserService;
  private actionQueue?: ActionQueueService;
  private whatsapp?: WhatsAppService;
  private mediaService?: MediaService; // Add MediaService
  private openai?: OpenAIService;
  private historyStore?: any; // HistoryStore or HistoryStorePostgres
  private vectorStore?: any; // VectorStoreService or VectorStoreServicePostgres
  private summaryStore?: SummaryStore;
  private isInitialized: boolean = false;

  constructor() {
    console.log('üöÄ Initializing Autonomous WhatsApp Agent...');
  }

  /**
   * Initialize all components of the autonomous system
   */
  async initialize(): Promise<void> {
    try {
      // 1. Initialize Core Services
      this.openai = await createOpenAIServiceFromConfig();
      this.contextMgr = new ContextManager();
      this.summaryStore = new SummaryStore();
      
      // Initialize database services using configuration switcher
      await DatabaseConfig.initialize();
      this.kb = DatabaseConfig.getKnowledgeBase(this.openai);
      this.historyStore = DatabaseConfig.getHistoryStore();
      this.vectorStore = DatabaseConfig.getVectorStoreService(this.openai);
      this.actionQueue = new ActionQueueService();

      // Set dependencies for ContextManager (rolling summarization)
      this.contextMgr.setDependencies(this.summaryStore, this.openai);

      // WhatsApp configuration
      const whatsappConfig = {
        accessToken: process.env.WHATSAPP_ACCESS_TOKEN || '',
        phoneNumberId: process.env.WHATSAPP_PHONE_NUMBER_ID || '',
        apiVersion: 'v19.0'
      };

      this.whatsapp = new WhatsAppService(whatsappConfig, process.env.DEV_MODE === 'true');
      this.mediaService = new MediaService(whatsappConfig); // Initialize MediaService

      // CRITICAL FIX: Link ActionQueue to WhatsApp Service
      this.actionQueue.registerMessageSender(async (userId, content) => {
        return this.whatsapp!.sendMessage(userId, content);
      });

      // 2. Initialize Browser & News Services
      const scraper = createWebScrapeService();
      this.browser = new BrowserService(scraper, this.kb);
      
      // Initialize News Stack
      // Mock GoogleSearchService for processor if not available, or initialize properly
      const searchService = createGoogleSearchServiceFromEnv();
      const newsProcessor = new NewsProcessorService(this.openai, searchService, this.vectorStore);
      const newsService = createNewsScrapeService(scraper, newsProcessor);

      // 3. Initialize Tool Registry
      this.tools = new ToolRegistry();
      
      // Register Web Search
      if (searchService) {
        this.tools.registerTool(new WebSearchTool(searchService));
      }

      // Register NEW Tools
      this.tools.registerTool(new RecallHistoryTool(this.historyStore));
      this.tools.registerTool(new ScrapeNewsTool(newsService));
      
      // Register Deep Research Tool
      if (this.browser) {
          this.tools.registerTool(new DeepResearchTool(this.browser));
      }

      // 4. Initialize Agent
      this.agent = new Agent(this.openai, this.contextMgr, this.kb, this.tools, this.actionQueue);

      // 5. Initialize Scheduler
      this.scheduler = new Scheduler(
        this.browser,
        this.contextMgr,
        this.whatsapp,
        this.agent,
        this.actionQueue,
        this.kb
      );

      this.isInitialized = true;
      console.log('‚úÖ Autonomous WhatsApp Agent Initialized Successfully');
      
      // Start background news service
      newsService.startBackgroundService(30);

    } catch (error) {
      console.error('‚ùå Failed to initialize Autonomous Agent:', error);
      throw error;
    }
  }

  /**
   * Initialize and register all tools
   */
  private async initializeTools(): Promise<void> {
    try {
      // Initialize Google Search Service if configured
      let searchService: GoogleSearchService | undefined;
      try {
        searchService = createGoogleSearchServiceFromEnv();
        console.log('‚úÖ Google Search Service initialized');
      } catch (error) {
        console.log('‚ö†Ô∏è Google Search Service not configured (missing API keys)');
      }
      
      // Register Web Search Tool if available
      if (searchService) {
        const webSearchTool = new WebSearchTool(searchService);
        this.tools!.registerTool(webSearchTool);
        console.log('üîç Web Search Tool registered');
      }
      
      console.log(`üõ†Ô∏è Tool Registry: ${this.tools!.getAvailableTools().length} tools available`);
      
      if (this.tools!.getAvailableTools().length === 0) {
        console.log('‚ö†Ô∏è No tools available - agent will rely on knowledge base only');
      }
      
    } catch (error) {
      console.error('‚ùå Tool initialization failed:', error);
      console.log('‚ö†Ô∏è Continuing with knowledge base only');
    }
  }

  /**
   * Start the autonomous agent system
   */
  start(): void {
    if (!this.isInitialized || !this.scheduler) {
      throw new Error('Agent must be initialized before starting');
    }

    console.log('\n' + '='.repeat(60));
    console.log('ü§ñ AUTONOMOUS WHATSAPP AGENT STARTING');
    console.log('='.repeat(60));

    // Start the scheduler (1-minute ticks)
    this.scheduler.start();

    console.log('üìç Scheduler: 1-minute autonomous tick cycle started');
    console.log('üåê Browser: Autonomous surfing enabled');
    console.log('üí¨ Agent: Proactive messaging capabilities active');
    console.log('üß† Memory: 3-tier memory system operational');
    console.log('üì¨ Queue: Rate-limited action queue running');

    if (process.env.DEV_MODE === 'true') {
      console.log('\nüí° DEVELOPMENT MODE: Messages will be logged to console');
      console.log('üö´ No messages will be sent to WhatsApp');
    }

    console.log('='.repeat(60) + '\n');
  }

  /**
   * Handle incoming WhatsApp messages (webhook integration)
   */
  async handleIncomingMessage(userId: string, message: string, messageId: string): Promise<void> {
    if (!this.isInitialized || !this.agent || !this.whatsapp) {
      throw new Error('Agent not initialized');
    }

    // 1. INTERRUPT BACKGROUND TASKS
    if (this.scheduler) {
        this.scheduler.interrupt();
    }

    console.log(`üì± Incoming message from ${userId}: ${message.substring(0, 50)}...`);

    try {
      // LOG USER MESSAGE TO HISTORY
      if (this.historyStore) {
        await this.historyStore.storeMessage({
          userId,
          message: message,
          role: 'user',
          timestamp: new Date().toISOString(),
          messageType: 'text',
          metadata: { messageId }
        });
      }

      // Process through the agent
      const response = await this.agent.handleUserMessage(userId, message);

      // LOG AGENT RESPONSE TO HISTORY
      if (this.historyStore) {
        await this.historyStore.storeMessage({
          userId,
          message: response,
          role: 'assistant',
          timestamp: new Date().toISOString(),
          messageType: 'text'
        });
      }

      // Send response via WhatsApp (or log in dev mode)
      if (process.env.DEV_MODE === 'true') {
        console.log(`üí¨ Response to ${userId}: ${response}`);
      } else {
        await this.whatsapp.sendMessage(userId, response);
      }

      console.log(`‚úÖ Message processed for ${userId}`);

    } catch (error) {
      console.error(`‚ùå Error processing message from ${userId}:`, error);
      
      // Fallback response
      const fallback = "Sorry, I encountered an issue. Please try again.";
      if (process.env.DEV_MODE !== 'true') {
        await this.whatsapp.sendMessage(userId, fallback);
      }
    }
  }

  /**
   * NEW: Handle incoming Image messages
   */
  async handleImageMessage(userId: string, imageId: string, mimeType: string, sha256: string, caption?: string): Promise<void> {
    if (!this.isInitialized || !this.agent || !this.whatsapp || !this.mediaService) {
      throw new Error('Agent not initialized');
    }

    // 1. INTERRUPT BACKGROUND TASKS
    if (this.scheduler) {
        this.scheduler.interrupt();
    }

    console.log(`üñºÔ∏è Incoming IMAGE from ${userId}`);

    try {
      // 1. Download Media
      const mediaInfo = await this.mediaService.downloadAndSaveMedia(imageId, mimeType, sha256, 'image');
      
      // 2. Analyze using Vision AI
      console.log(`üëÅÔ∏è Analyzing image: ${mediaInfo.filename}`);
      const analysis = await this.mediaService.analyzeImageWithOpenAI(mediaInfo.filepath);
      
      // LOG USER MESSAGE (IMAGE) TO HISTORY
      // We store the analysis in the message text so it's searchable via Recall tool
      if (this.historyStore) {
        const storedMessage = caption ? `${caption} [Image Analysis: ${analysis}]` : `[Image Analysis: ${analysis}]`;
        await this.historyStore.storeMessage({
          userId,
          message: storedMessage,
          role: 'user',
          timestamp: new Date().toISOString(),
          messageType: 'image',
          metadata: {
              imageId,
              mimeType,
              filepath: mediaInfo.filepath,
              analysis,
              caption
          }
        });
      }

      // 3. Construct Augmented Message for Agent
      // We present the image analysis as system context or augmented user message
      const augmentedMessage = `[USER SENT AN IMAGE]\n\nImage Analysis:\n${analysis}\n\n${caption ? `User Caption: "${caption}"` : 'No caption provided.'}`;
      
      console.log(`üìù Processing analyzed image as text context...`);
      
      // 4. Pass to standard agent handler
      const response = await this.agent.handleUserMessage(userId, augmentedMessage);

      // LOG AGENT RESPONSE
      if (this.historyStore) {
        await this.historyStore.storeMessage({
          userId,
          message: response,
          role: 'assistant',
          timestamp: new Date().toISOString(),
          messageType: 'text'
        });
      }

      if (process.env.DEV_MODE === 'true') {
        console.log(`üí¨ Response to ${userId}: ${response}`);
      } else {
        await this.whatsapp.sendMessage(userId, response);
      }

      console.log(`‚úÖ Image processed for ${userId}`);

    } catch (error) {
      console.error(`‚ùå Error processing image from ${userId}:`, error);
      const fallback = "I received your image but had trouble analyzing it. Please try again.";
      if (process.env.DEV_MODE !== 'true') {
        await this.whatsapp.sendMessage(userId, fallback);
      }
    }
  }

  /**
   * NEW: Handle incoming Audio messages
   * Workflow: Download -> Transcribe -> AI Response -> Synthesize (TTS) -> Send Audio
   */
  async handleAudioMessage(userId: string, audioId: string, mimeType: string, sha256: string): Promise<void> {
    if (!this.isInitialized || !this.agent || !this.whatsapp || !this.mediaService) {
      throw new Error('Agent not initialized');
    }

    // 1. Interrupt background tasks
    if (this.scheduler) this.scheduler.interrupt();

    console.log(`üé§ Incoming AUDIO from ${userId}`);

    try {
      // 2. Download Audio
      const mediaInfo = await this.mediaService.downloadAndSaveMedia(audioId, mimeType, sha256, 'audio');
      
      // 3. Convert audio to WAV format for better transcription (fixes OGG/Opus issues)
      console.log(`üîÑ Converting audio to WAV format: ${mediaInfo.filename}`);
      const convertedAudioPath = await this.mediaService.convertAudioToWav(mediaInfo.filepath);
      
      // 4. Transcribe (Speech-to-Text)
      console.log(`üëÇ Transcribing audio: ${convertedAudioPath}`);
      // Assuming 'en' or auto-detect. You can change 'en' to undefined to auto-detect if supported.
      const transcription = await this.mediaService.transcribeAudio(convertedAudioPath);
      console.log(`üìù User said: "${transcription}"`);

      // LOG USER MESSAGE (AUDIO) TO HISTORY
      if (this.historyStore) {
        await this.historyStore.storeMessage({
          userId,
          message: transcription || '[Unintelligible Audio]',
          role: 'user',
          timestamp: new Date().toISOString(),
          messageType: 'audio',
          metadata: {
              audioId,
              mimeType,
              filepath: mediaInfo.filepath
          }
        });
      }

      // 4. Get Agent Text Response
      // We pass the transcription as if the user typed it
      const textResponse = await this.agent.handleUserMessage(userId, transcription);

      // LOG AGENT RESPONSE
      if (this.historyStore) {
        await this.historyStore.storeMessage({
          userId,
          message: textResponse,
          role: 'assistant',
          timestamp: new Date().toISOString(),
          messageType: 'text'
        });
      }

      // 5. Synthesize Response (Text-to-Speech)
      console.log(`üó£Ô∏è Synthesizing voice response...`);
      const audioResponse = await this.mediaService.synthesizeAudio(textResponse, {
        voice: 'af_heart', // You can change the voice here
        speed: 1.0
      });

      // 6. Convert WAV to WhatsApp-compatible format (OGG)
      console.log(`üîÑ Converting audio to WhatsApp-compatible format...`);
      const convertedAudio = await this.mediaService.convertAudioToWhatsAppFormat(audioResponse.filepath, 'ogg');

      // 7. Upload Converted Audio to WhatsApp
      const uploadedMediaId = await this.whatsapp.uploadMedia(convertedAudio.filepath, convertedAudio.mimeType);

      if (uploadedMediaId) {
        // 8. Send Audio Message
        await this.whatsapp.sendAudioMessage(userId, uploadedMediaId);
        
        // Optional: Also send the text version for clarity
        // await this.whatsapp.sendMessage(userId, `(Transcript): ${textResponse}`);
      } else {
        // Fallback to text if upload fails
        await this.whatsapp.sendMessage(userId, textResponse);
      }

      console.log(`‚úÖ Voice interaction completed for ${userId}`);

    } catch (error) {
      console.error(`‚ùå Error processing audio from ${userId}:`, error);
      const fallback = "I heard you, but had trouble processing the audio. Please type your message instead.";
      if (process.env.DEV_MODE !== 'true') {
        await this.whatsapp.sendMessage(userId, fallback);
      }
    }
  }

  /**
   * Handle web interface messages (returns response instead of sending)
   * Supports optional attachment (simulated upload)
   * Returns object with text and optional audio (base64)
   */
  async handleWebMessage(userId: string, message: string, attachment?: { type: 'image' | 'audio', filePath: string }): Promise<{ text: string, audio?: string }> {
    if (!this.isInitialized || !this.agent) {
      throw new Error('Agent not initialized');
    }

    // 1. INTERRUPT BACKGROUND TASKS
    if (this.scheduler) {
        this.scheduler.interrupt();
    }

    console.log(`üåê Web message from ${userId}: ${message.substring(0, 50)}... ${attachment ? `[With ${attachment.type}]` : ''}`);

    try {
      let processedMessage = message;
      let analysisResult = '';

      // Handle Attachment logic simulating real media processing
      if (attachment && this.mediaService) {
        if (attachment.type === 'image') {
          console.log(`üëÅÔ∏è Analyzing web image attachment: ${attachment.filePath}`);
          const analysis = await this.mediaService.analyzeImageWithOpenAI(attachment.filePath);
          processedMessage = `[USER SENT AN IMAGE]\n\nImage Analysis:\n${analysis}\n\n${message ? `User Caption: "${message}"` : ''}`;
          analysisResult = analysis;
        } else if (attachment.type === 'audio') {
          console.log(`üé§ Transcribing web audio attachment: ${attachment.filePath}`);
          // Convert audio to WAV format for better transcription
          const convertedAudioPath = await this.mediaService.convertAudioToWav(attachment.filePath);
          const transcription = await this.mediaService.transcribeAudio(convertedAudioPath);
          console.log(`üìù Transcription: "${transcription}"`);
          processedMessage = transcription;
          if (message) processedMessage += `\n\n(User Note: ${message})`;
        }
      }

      // LOG USER MESSAGE
      if (this.historyStore) {
        // Calculate what to store. If it's an image, include analysis for searchability.
        let storeMsg = message;
        let msgType: 'text'|'image'|'audio' = 'text';

        if (attachment) {
            msgType = attachment.type;
            if (attachment.type === 'image') {
                storeMsg = message ? `${message} [Image Analysis: ${analysisResult}]` : `[Image Analysis: ${analysisResult}]`;
            } else if (attachment.type === 'audio') {
                storeMsg = processedMessage; // The transcription
            }
        }

        await this.historyStore.storeMessage({
          userId,
          message: storeMsg,
          role: 'user',
          timestamp: new Date().toISOString(),
          messageType: msgType,
          metadata: attachment ? { filePath: attachment.filePath } : undefined
        });
      }

      // Process through the agent but don't send via WhatsApp
      // Note: For image attachments, we pass the 'processedMessage' (augmented with analysis) to the agent
      // For audio, we pass the transcription
      // For text, just the text
      const inputToAgent = attachment ? processedMessage : message;
      const responseText = await this.agent.handleUserMessage(userId, inputToAgent);
      
      // LOG AGENT RESPONSE
      if (this.historyStore) {
        await this.historyStore.storeMessage({
          userId,
          message: responseText,
          role: 'assistant',
          timestamp: new Date().toISOString(),
          messageType: 'text'
        });
      }

      let audioData: string | undefined;

      // Generate TTS Audio response if input was audio
      if (attachment && attachment.type === 'audio' && this.mediaService) {
          try {
              console.log(`üó£Ô∏è Generating audio response for Web UI...`);
              const audioInfo = await this.mediaService.synthesizeAudio(responseText);
              
              if (fs.existsSync(audioInfo.filepath)) {
                  const buffer = fs.readFileSync(audioInfo.filepath);
                  // Convert to base64 Data URI
                  audioData = `data:${audioInfo.mimeType};base64,${buffer.toString('base64')}`;
              }
          } catch (e) {
              console.error('Failed to synthesize audio for web response:', e);
          }
      }

      console.log(`‚úÖ Web message processed for ${userId}`);
      return { text: responseText, audio: audioData };
    } catch (error) {
      console.error(`‚ùå Error processing web message from ${userId}:`, error);
      return { text: "Sorry, I encountered an issue processing your message. Please try again." };
    }
  }

  /**
   * Get system status and statistics
   */
  async getStatus() {
    if (!this.isInitialized || !this.agent || !this.scheduler || !this.contextMgr || !this.kb || !this.browser || !this.actionQueue || !this.tools) {
      return { status: 'Not initialized' };
    }

    const dbStats = await DatabaseConfig.getDatabaseStats();

    return {
      status: 'Running',
      database: dbStats,
      agent: this.agent.getStats(),
      scheduler: this.scheduler.getStatus(),
      memory: {
        context: this.contextMgr.getStats(),
        knowledge: await (this.kb as any).getStats()
      },
      browser: this.browser.getStats(),
      queue: this.actionQueue.getQueueStats(),
      tools: {
        available: this.tools.getAvailableTools(),
        count: this.tools.getAvailableTools().length
      }
    };
  }

  /**
   * Get actual knowledge content for dashboard display
   */
  async getKnowledgeContent(limit: number = 10): Promise<Array<{id: string; title: string; content: string; source: string; category: string; timestamp: string}>> {
    if (!this.isInitialized || !this.kb) {
      return [];
    }
    
    try {
      const documents = await (this.kb as any).getRecentDocuments(limit);
      return documents.map((doc: any) => ({
        id: doc.id,
        title: `${doc.category} - ${doc.source}`,
        content: doc.content,
        source: doc.source,
        category: doc.category,
        timestamp: doc.timestamp
      }));
    } catch (error) {
      console.error('Error getting knowledge content:', error);
      return [];
    }
  }

  /**
   * Search knowledge content for dashboard
   */
  async searchKnowledgeContent(query: string, limit: number = 10): Promise<Array<{id: string; title: string; content: string; source: string; category: string; timestamp: string}>> {
    if (!this.isInitialized || !this.kb) {
      return [];
    }
    
    try {
      const documents = await (this.kb as any).searchContent(query, limit);
      return documents.map((doc: any) => ({
        id: doc.id,
        title: `${doc.category} - ${doc.source}`,
        content: doc.content,
        source: doc.source,
        category: doc.category,
        timestamp: doc.timestamp
      }));
    } catch (error) {
      console.error('Error searching knowledge content:', error);
      return [];
    }
  }

  /**
   * Stop the autonomous system
   */
  stop(): void {
    if (this.scheduler) {
      this.scheduler.stop();
    }
    console.log('üõë Autonomous WhatsApp Agent Stopped');
  }

  /**
   * Log initial system statistics
   */
  private logInitialStats(): void {
    console.log('üìä Initial System Stats:');
    console.log('- Memory: 3-tier architecture (1h context, vector KB, SQL history)');
    console.log('- Browser: Autonomous surfing with 10 pages/hour limit');
    console.log('- Scheduler: 1-minute ticks with intelligent mode switching');
    console.log('- Agent: LLM orchestration with tool calling');
    console.log('- Queue: Rate-limited messaging with proactive cooldowns');
  }
}

// Singleton instance
let autonomousAgent: AutonomousWhatsAppAgent;

/**
 * Get or create the autonomous agent instance
 */
export function getAutonomousAgent(): AutonomousWhatsAppAgent {
  if (!autonomousAgent) {
    autonomousAgent = new AutonomousWhatsAppAgent();
  }
  return autonomousAgent;
}

/**
 * Initialize and start the autonomous agent
 */
export async function startAutonomousAgent(): Promise<AutonomousWhatsAppAgent> {
  const agent = getAutonomousAgent();
  await agent.initialize();
  agent.start();
  return agent;
}

// Export for testing and manual control
export { AutonomousWhatsAppAgent };